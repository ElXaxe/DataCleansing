{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.951 - Tipologia i cicle de vida de les dades</p>\n",
    "<p style=\"margin: 0; text-align:right;\">2017-2 · Màster universitari en Ciència de dades (Data science)</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\"><b>Autors:</b> Joan Bonnín i Jose L. Dolz</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width:100%;\">&nbsp;</div>\n",
    "\n",
    "\n",
    "# Pràctica 2: Neteja i validació de les dades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripció \n",
    "L’objectiu d’aquesta activitat serà el tractament d’un *dataset*, que pot ser el creat a la pràctica 1 o bé qualsevol dataset lliure disponible a Kaggle (https://www.kaggle.com). Alguns exemples de *dataset* amb els que podeu treballar són:\n",
    "<ul>\n",
    "    <li>Red Wine Quality (https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009).</li>\n",
    "    <li>Titanic: Machine Learning from Disaster (https://www.kaggle.com/c/titanic).</li>\n",
    "    <li>Predict Future Sales (https://www.kaggle.com/c/competitive-data-science-predict-future-sales/).</li>\n",
    "</ul>\n",
    "Els últims dos exemples corresponen a competicions actives a Kaggle de manera que, opcionalment, podríeu aprofitar el treball realitzat durant la pràctica per entrar en alguna d’aquestes competicions.\n",
    "Seguint les principals etapes d’un projecte analític, les diferents tasques a realitzar (i <b>justificar</b>) són les següents:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATENCIÓ: Es important tenir instal·lats al sistema els següents\n",
    "# paquets: pandas, numpy, scipy, matplotlib, sklearn, pydotplus, graphviz\n",
    "#\n",
    "# Si se està utilitzan Python 3, la forma d'instal·lar un paquet és\n",
    "# executant la següent ordre des de la línia de comandes:\n",
    "# > pyp3 install nom_paquet\n",
    "\n",
    "# Basic maths & data structures\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "# Data rendering\n",
    "from IPython.display import display\n",
    "from IPython.display import Image  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Linear model\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Render tree\n",
    "from sklearn.externals.six import StringIO  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General constants\n",
    "PVAL_THRESHOLD = 0.05\n",
    "RANDOM_SEED = 2018\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Descripció del dataset. Perquè és important i quina pregunta/problema pretèn respondre?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#1111aa\">\n",
    "    Per aquesta pràctica hem escollit el conjunt de dades de <a href=\"https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009\" target=\"_blank\">la qualitat del vi negre</a> que, com bé s'explica en la seva pàgina de Kaggle, tracta de les variants del vi portuguès conegut com <a href=\"http://www.vinhoverde.pt/en/\" target=\"_blank\">'Vinho Verde'</a>. Els <b>camps</b> que composen el dataset són tots <b>numèrics</b> i són els següents:\n",
    "    <ul>\n",
    "        <li><b>fixed acidity</b>: acidesa fixa (<i>g/l</i>). Majoria dels àcids fixos o no volàtils fàcilment.</li>\n",
    "        <li><b>volatile acidity</b>: acidesa volàtil (<i>g/l</i>). Quantitat d'àcid acètic que en gran quantitat porta al vi a tenir gust de vinagre.</li>\n",
    "        <li><b>citric acid</b>: àcid cítric (<i>g/l</i>). Quantitat d'aquest àcid (normalment petita) que pot donar sabor i frescor als vins</li>\n",
    "        <li><b>residual sugar</b>: sucre residual (<i>g/l</i>). Quantitat de sucre que queda després de la fermentació. És estrany trobar vins amb menys d'1 g/l i els que tenen més de 45 g/l es consideren dolços.</li>\n",
    "        <li><b>chlorides</b>: clorurs (<i>g/l</i>). Representa la quantitat de sal al vi.</li>\n",
    "        <li><b>free sulfur dioxide</b>: diòxid de sofre lliure o SO2 (<i>mg/l</i>). Parts per milió (ppm) del diòxid que queda lliure un cop es barreja en barrejar-se amb el vi. </li>\n",
    "        <li><b>total sulfur dioxide</b>: Diòxid de sofre total (<i>mg/l</i>). La suma (en ppm) de la part lliure i la part fixada al vi de SO2.</li>\n",
    "        <li><b>density</b>: densitat (<i>g/l</i>). Aquest valor dependrà de la quantitat d'alcohol i sucre en el vi. </li>\n",
    "        <li><b>pH</b>: descriu com d'àcid o bàsic és un vi en una escala de 0 (molt àcid) a 14 (molt bàsic); La majoria dels vins són entre 3 i 4 en l'escala de pH.</li>\n",
    "        <li><b>sulphates</b>: sulfats (<i>g/l</i>), que contribueixen al SO2.</li> Aquest component prevé al vi de bacteris i de l'oxidació.\n",
    "        <li><b>alcohol</b>: percentatge de contingut alcohòlic en el vi. Volum d'etanol / Volum del producte</li>\n",
    "        <li><b>quality</b>: qualitat del vi en una puntuació entre el 0 i el 10.</li>\n",
    "    </ul>\n",
    "<p>Com podem veure, tenim els 12 atributs: 11 mesures físico-químiques i la qualitat, que podríem dir que és la classe.</p>\n",
    "    <p>Aquest conjunt de dades és important perquè ens pot servir perquè, mitjançant proves de correlació, podem veure quins atributs són més influents a l'hora de millorar o empitjorar la qualitat d'un vi. A més, entrenarem un model complex d'aprenentatge computacional que podrà predir la qualitat d'un vi, mitjançant aquestes dades físico-químiques obtingudes pels diferents instruments de mesurament.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Integració i selecció de les dades d’interès a analitzar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df = pd.read_csv('winequality-red.csv')\n",
    "print(\"El conjunt de dades presenta {} camps i està compost per {} registres.\".format(wine_df.shape[1], wine_df.shape[0]))\n",
    "display(wine_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#1111aa\">\n",
    "    <p>Com podem observar en la taula, tots els atributs presenten valors numèrics continus que ens poden servir per cercar una relació lineal amb el valor discret de la qualitat. En aquest punt, no podem prescindir de cap d'aquests atributs doncs no sabem quina és la seva relació amb la nota de qualitat. Per tant, no ens desfarem de cap.\n",
    "    </p>\n",
    "    <p>\n",
    "        Per altra banda, crearem un atribut categòric booleà que etiqueti si un vi és bo o dolent, depenent de la seva nota. En el nostre cas, escollim que els bons vins són aquells que tenen una puntuació de qualitat de 6 o superior. Aquest atribut ens servirà com a classificador per la creació d'un model basat en *Random Forests*.\n",
    "    </p>\n",
    "    </font>\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Neteja de les dades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Les dades contenen zeros o elements buits? Com gestionaries aquests casos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contem els valors nuls\n",
    "n_nulls = wine_df[wine_df.isnull()].count()\n",
    "\n",
    "# Contem els zeros\n",
    "n_zeros = wine_df[wine_df == 0].count()\n",
    "\n",
    "df_empties = pd.DataFrame()\n",
    "df_empties[\"Nombre de Nulls\"] = n_nulls\n",
    "df_empties[\"Nombre de zeros\"] = n_zeros\n",
    "display(df_empties.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#1111aa\">\n",
    "<p>\n",
    "    Com podem observar, no tenim cap atribut que presenti valors nuls. Per altra banda, només trobem zeros en l'atribut d'àcid cítric. Concretament, tenim 132 zeros d'un total de 1599 registres, el que representa un 8'26% del total.</p>\n",
    "\n",
    "<p>\n",
    "    En aquest cas, no cal que substituïm els zeros per cap altre valor. És totalment normal trobar vins negres sense àcid cítric, fet que els hi dóna un sabor més anyenc. De fet, com veurem més endavant, el rang de grams per litre de l'àcid cítric en vins negres és molt petit i el zero estaria dintre dels barems. Fins i tot podem trobar vins blancs amb zero grams d'àcid cítric, tot i que en aquests acostuma a haver-hi unes quantitats més altes que als vins negres.</p>\n",
    "    \n",
    "<p>\n",
    "    Així doncs, podem observar que en aquest sentit, pel que fa a zeros i valors nuls, el *dataset* està completament net des de l'inici. És bastant raonable pensar que Kaggle ha realitzat una tasca prèvia de neteja per facilitar l'ús de les dades amb intencions analítiques, sense haver de dedicar gaire esforç a la neteja inicial.</p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Identificació i tractament de valors extrems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dibueixem un boxplot per cada atribut per veure màxims, \n",
    "# mínims, quartils, rang interquartilic i outliers.\n",
    "\n",
    "df_cols = list(wine_df)\n",
    "n_rows = 2\n",
    "n_cols = 6\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(30, 15))\n",
    "for i, row_axes in enumerate(axes):\n",
    "    for j, ax in enumerate(row_axes):\n",
    "        idx = i*n_cols + j\n",
    "        wine_df.boxplot(column=df_cols[idx], ax=axes[i][j], grid=False)\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#1111aa\">\n",
    "<p>Als *boxplots* s'observa que la majoria de variables presenten una quantitat elevada d'*outliers*, així que val la pena aplicar-hi una anàlisi més extensa per detectar si es tracta de presència de valors erronis o la realitat de les dades és la que es mostra.\n",
    "    </p>\n",
    "    <p>\n",
    "El fet que la majoria d'*outliers* s'agrupin a prop dels bigotis i la densitat baixi segons s'allunyen, ens fa pensar que els valors poden ser correctes, i que simplement la distribució presenta una desviació lateral o una variància molt elevada. Un exemple habitual per mostrar dades que presenten aquesta característica són els salaris.\n",
    "        </p>\n",
    "</font>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Anàlisi de les dades.\n",
    "### 4.1. Selecció dels grups de dades que es volen analitzar/comparar (planificació dels anàlisis a aplicar)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"darkblue\">\n",
    "    <p>\n",
    "        No descartarem cap dels atributs que ofereix el conjunt de dades proporcionat perquè volem esbrinar quins són els que tenen més importància, quins ofereixen una distribució normal i quins no, com és la relació de variàncies, l'anàlisi de correlacions i, finalment, un model de classificació.\n",
    "    </p>\n",
    "        \n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Comprovació de la normalitat i homogeneïtat de la variància."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"darkblue\">\n",
    "    <p>\n",
    "        El Teorema del Límit Central ens diu que qualsevol població amb un nombre d'elements prou gran tendeix a una distribució normal estàndard. En el nostre cas, considerem que aquest Teorema es pot aplicar quan N > 30. Per tant, el nostre conjunt tendeix a una distribució normal.\n",
    "    </p>\n",
    "    <p>\n",
    "        De totes maneres, a continuació fem servir histogrames i el test de normalitat d'Anderson-Darling per assegurar-nos:\n",
    "    </p>\n",
    "</font>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####### NORMALITAT #######\n",
    "\n",
    "# Mètodes gràfics \n",
    "def render_normality_histograms():\n",
    "    n_rows = 3\n",
    "    n_cols = 4\n",
    "    n_bars = 30\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(30, 15))\n",
    "    for i, row_axes in enumerate(axes):\n",
    "        for j, ax in enumerate(row_axes):\n",
    "            idx = i*n_cols + j\n",
    "\n",
    "            attr = df_cols[idx]\n",
    "            ax.set_xlabel(attr)      \n",
    "\n",
    "            data = wine_df[attr].sort_values()\n",
    "            ax.hist(data, bins=n_bars, density=True)\n",
    "\n",
    "            norm = stats.norm.pdf(data, np.mean(data), np.std(data))\n",
    "            ax.plot(data, norm) \n",
    "    plt.show()\n",
    "    \n",
    "def render_normality_table():\n",
    "    (anderson_true, anderson_false) = test_normality_anderson()\n",
    "       \n",
    "    anderson = merge_normality_results(anderson_true, anderson_false)\n",
    "    \n",
    "    normality_res = pd.DataFrame([anderson],\n",
    "                                 index=[\"Test Anderson-Darling\"])\n",
    "    normality_res.columns.name = \"Segueix distribució normal?\"\n",
    "    display(normality_res)\n",
    "        \n",
    "        \n",
    "# Mètodes numèrics\n",
    "def test_normality_anderson(p_value_threshold=PVAL_THRESHOLD, render=False):\n",
    "    normal_attrs = []\n",
    "    non_normal_attrs = []\n",
    "    for attr_key in wine_df:\n",
    "        attr = wine_df[attr_key].values\n",
    "        res = stats.anderson(attr, dist='norm')\n",
    "        stat = res.statistic\n",
    "        threshold = res.critical_values[2] #0.05 significance == PVAL_THRESHOLD\n",
    "        if stat > threshold:\n",
    "            normal_attrs.append(attr_key)\n",
    "        else:\n",
    "            non_normal_attrs.append(attr_key)\n",
    "            \n",
    "    if render:\n",
    "        print_attrs_distributions(normal_attrs, non_normal_attrs)\n",
    "        \n",
    "    return (normal_attrs, non_normal_attrs)\n",
    "\n",
    "    \n",
    "def print_attrs_distributions(normal, non_normal):\n",
    "    print(\"Atributs amb distribució normal: {}\".format(normal))\n",
    "    print(\"Atributs amb distribució no normal: {}\".format(non_normal))\n",
    "\n",
    "    \n",
    "def merge_normality_results(normal, non_normal):\n",
    "    dict_normal = {k: '✓' for k in normal}\n",
    "    dict_non_normal = {k: '✗' for k in non_normal}\n",
    "    \n",
    "    #inplace_merging\n",
    "    dict_normal.update(dict_non_normal)    \n",
    "    return dict_normal\n",
    "\n",
    "render_normality_histograms()\n",
    "render_normality_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#1111aa\">\n",
    "    <p>\n",
    "        El test d'Anderson-Darling ens mostra com tots els atributs segueixen una distribució normal. Això també ho corrobora els histogrames i la corba de distribució normal. Tot i això, amb grans conjunts de dades, els tests numèrics sobre normalitat no són gaire fiables. Per tant, tal com veiem a les corbes i el que hem comentat sobre el Teorema del Límit Central, considerarem que tots els atributs segueixen una distribució normal.\n",
    "    </p>\n",
    "    <p>\n",
    "        Per avaluar l'homogeneitat de la variància disposem de diferents tècniques i eines. Entre les més conegudes trobem *Levene* i *Fligner*, així que passem a aplicar-los mitjançant la implementació d'Scipy.\n",
    "    </p>\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### HOMOGENEITAT VARIANCIA #######\n",
    "\n",
    "# Levene és util si la normalitat no està asegurada\n",
    "def levene_test(threshold=PVAL_THRESHOLD):\n",
    "    res = stats.levene(*wine_df.as_matrix(), center='median') # Expand matrix to n parameters with '*'\n",
    "    return res.pvalue\n",
    "#     return res\n",
    "    p = res.pvalue\n",
    "    pprint((\"Levene\", p))\n",
    "    return p > threshold\n",
    "\n",
    "def fligner_test(threshold=PVAL_THRESHOLD):\n",
    "    res = stats.fligner(*wine_df.as_matrix(), center='median') # Expand matrix to n parameters with '*'\n",
    "    return res.pvalue\n",
    "#     return res\n",
    "    p = res.pvalue\n",
    "    pprint((\"Flinger\", p))\n",
    "    return p > threshold\n",
    "\n",
    "\n",
    "variance_tests = [levene_test(), fligner_test()]\n",
    "are_equal = [p > PVAL_THRESHOLD for p in variance_tests]\n",
    "\n",
    "display(pd.DataFrame(\n",
    "    {\n",
    "        'Populations with equal variances?': are_equal,\n",
    "        'p-value': variance_tests\n",
    "    },\n",
    "    index=['Levene test', 'Fligner test']\n",
    ").T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"darkblue\">\n",
    "    <p>\n",
    "        Com podem observar, les poblacions passen el test de Levene i el test de Fligner i, per tant podem assegurar que existeix una homogeneïtat en les variàncies dels atributs.\n",
    "    </p>\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Aplicació de proves estadístiques per comparar els grups de dades. En funció de les dades i de l’objectiu de l’estudi, aplicar proves de contrast d’hipòtesis, correlacions, regressions, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"darkblue\">\n",
    "<p>Per aplicar diferents estudis sobre les dades, hem definit dues preguntes a respondre: *Quines característiques determinen la qualitat del vi?* i *Es pot inferir, a partir de la característica més important, la qualitat del vi?*\n",
    " </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "### Quines característiques determinen la qualitat del vi?\n",
    "\n",
    "<font color=\"darkblue\">\n",
    "<br><p>\n",
    "La primera aproximació per determinar quines variables tenen més pes sobre la qualitat final és cercar si existeix una correlació entre els atributs i la qualitat i quin és el pes de cadascun.\n",
    "    </p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mirem les correlacions entre els atributs i la qualitat\n",
    "data = np.ndarray(shape=(len(df_cols), 2))\n",
    "for i in range(len(df_cols)):\n",
    "    attr = df_cols[i]\n",
    "    data[i] = stats.pearsonr(wine_df[attr], wine_df['quality'])\n",
    "df_pearson = pd.DataFrame(data, index=df_cols, columns=['estimació', 'p-valor'])[:11]\n",
    "df_pearson['tmp_sort'] = df_pearson['estimació'].abs()\n",
    "df_pearson = df_pearson.sort_values(by='tmp_sort', ascending=False).drop('tmp_sort', axis=1)\n",
    "\n",
    "# Format output\n",
    "# pprint(df_pearson['estimació'].values)\n",
    "df_pearson['estimació'] = [\"{0:.4f}\".format(el) for el in df_pearson['estimació'].values]\n",
    "df_pearson['p-valor'] = [\"{0:.2e}\".format(el) for el in df_pearson['p-valor'].values]\n",
    "display(df_pearson.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#1111aa\">\n",
    "    <p>\n",
    "        Hem ordenat els atributs dels que més impacten a l'hora de determinar la qualitat als que menys. Tal i com podem observar, la qualitat augmenta gairebé un 50% segons el volum d'**alcohol** que tenim en el vi. Per altra banda, el 40% de quantitat d'**acidesa volàtil** influeix negativament en la qualitat. És a dir, com més sàpiga a vinagre, pitjor.\n",
    "    </p>\n",
    "    <p>\n",
    "        Seguidament tenim que el 25% de la quantitat de **sulfats** augmenten la qualitat. Sembla obvi, doncs aquest component ajuda que el vi no s'oxidi i impedeix l'aparició de bacteris. Però per altra banda, paradoxalment, el **SO2 total i el lliure** resten qualitat al vi (un 18'5%  i un 5% de la seva quantitat, respectivament). \n",
    "    </p>\n",
    "    <p>\n",
    "        L'**àcid cítric** suma el 22'6% del seu valor i podem deduir que un vi que sigui més fresc afavoreix a obtenir una millor nota. Per altra banda, com menys dens és el vi -menys líquid- pitjor la seva qualitat, restant un 17'5% del valor de la **densitat**. La quantitat de **clorurs** també afecta negativament, restant quasi un 13% del seu valor: com més salat estigui el vi, pitjor qualitat tindrà. Per altra banda, el valor del **sucre** només suma un 1'4% del seu valor. No ens ha de resultar xocant doncs estem parlant de vins negres i aquests no acostumen a ser dolços (tret que siguin escumosos, però no és el cas d'aquests). \n",
    "    </p>\n",
    "    <p>\n",
    "        Darrerament, tenim que el **pH**, que resta un 5% del seu valor a la qualitat final. És a dir, com més àcid sigui un vi, pitjor encara que no compti molt. Però, per altra banda, l'**acidesa fixa** suma a la qualitat del vi un 12'4% del seu valor. \n",
    "    </p>\n",
    "    <p>\n",
    "        Pel que fa als p-valors, podem descartar tots aquells atributs que superin el llindar de 0.05. Només el sucre supera aquest llindar i, per tant, no el faríem servir en un model de regressió lineal.\n",
    "    </p>\n",
    "</font>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlació dels atributs\n",
    "pd.plotting.scatter_matrix(wine_df.iloc[:, :11], figsize=(30,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#1111aa\">\n",
    "    <p>En el gràfic de correlacions entre parells d'atributs -considerant que són tots normals- podem veure clarament la relació directa que havíem explicat al principi entre el SO2 lliure i total: com més tenim d'un, més tenim de l'altre.</p>\n",
    "     <p>\n",
    "        Per altra banda, tenim atributs que es relacionen fortament entre si. Per exemple, com més àcid cítric, més acidesa fixa. Això ens fa pensar que pujant aquest dos paràmetres obtindríem millor nota perquè, a més, com més acidesa fixa, menys pH, que li resta qualitat. A més a més, com més àcid cítric, menys acidesa volàtil i, per tant, menys sabor a vinagre. Però tenim el problema que com més quantitat d'acidesa fixa, derivada de l'àcid cítric, augmentem també la seva densitat, que va en detriment de la qualitat. Com veiem, trobar els paràmetres físico-químics equilibrats per treure un vi de molt bona qualitat és una tasca força feixuga. \n",
    "    </p>\n",
    "    <p>\n",
    "        A continuació, construirem un model de predicció. Serà una combinació d'arbres de decisió entrenats amb bagging (usant mostreig amb reemplaçament), també conegut com Random Forests. Hem escollit aquest classificador per diferents motius: curiositat acadèmica, aproximar-nos al treball amb eines d'entorns reals i, principalment, que és un model amb el coneixement accessible.\n",
    "    </p>\n",
    "    <p>\n",
    " Això vol dir que, a diferència d'altres models molt coneguts com les xarxes neuronals, el model descriu perfectament perquè es comporta com ho fa. Donat que la pregunta que volem resoldre és conèixer els factors amb més pes per definir la qualitat del vi, el model *Random Forest* sembla el candidat idoni per aquesta tasca.\n",
    "    </p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inserció d'atribut qualitatiu per la qualitat del vi\n",
    "CLASSES_NAMES = ['Bad wine', 'Good wine']\n",
    "GOOD_THRESHOLD = 6\n",
    "raw_y = wine_df['quality'] >= GOOD_THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_raw_y(raw_y):    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    y = le.fit_transform(raw_y)\n",
    "    return y\n",
    "\n",
    "def random_forest_preprocess_data(df, raw_y):\n",
    "    #Input data\n",
    "    X = df.drop(['quality'], axis=1)\n",
    "    #Labels\n",
    "    y = encode_raw_y(raw_y)\n",
    "    return (X, y)\n",
    "\n",
    "def split_train_test(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.15, random_state=RANDOM_SEED\n",
    "    )\n",
    "    return (X_train, X_test, y_train, y_test)\n",
    "\n",
    "def display_precission(score):\n",
    "    print(\"Precisió del model: {} %\".format(round(score*100, 2)))\n",
    "\n",
    "(X, y) = random_forest_preprocess_data(wine_df, raw_y)\n",
    "(X_train, X_test, y_train, y_test) = split_train_test(X, y)\n",
    "\n",
    "rfc_model = RandomForestClassifier(bootstrap=True, n_estimators = 150, n_jobs=8, random_state=RANDOM_SEED)\n",
    "rfc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_score = rfc_model.score(X_test, y_test)\n",
    "display_precission(rfc_score)\n",
    "# pprint(rfc_model.feature_importances_)\n",
    "importances_df = pd.DataFrame(\n",
    "    rfc_model.feature_importances_,\n",
    "    index=list(X_test),\n",
    "    columns=['Importància']\n",
    ")\n",
    "importances_df = importances_df.sort_values(by=\"Importància\", ascending=False)\n",
    "display(importances_df.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"darkblue\">\n",
    "    <p>Com podem veure, la importància que atorga als atributs el nostre model basat en boscos aleatoris (*Random Forests*) són bastant semblants als obtinguts en la correlació lineal, sent l'alcohol el de major pes i el sucre residual el que menys. No hem de confondre els pesos que dóna el *Random Forest* als atributs (on la seva suma és 1) amb els factors donats en la correlació lineal amb la qualitat.\n",
    "    </p>\n",
    "    <p>\n",
    "        Per altra banda, obtenim una precisió prou alta encara que una mica per sota del llindar del 80% al qual estem acostumats a donar per bo el model. Hem de tenir en compte que un model complex com són els *Random Forests* millora la seva precisió com més gran és el seu conjunt d'entrenament. Per tant, podem assegurar que utilitzant les dades dels vins de collites d'altres anys -recordem que estem fent servir només l'any 2009- millorarem la precisió de manera que aquest model podrà determinar de forma més exacta la qualitat de vins futurs.\n",
    "    </p>\n",
    "    <p>\n",
    "        Una vegada hem realitzat aquestes diferents proves i anàlisis, podem dir clarament que la característica amb més pes per determinar la qualitat del vi, sorprenentment, és el nivell d'alcohol.\n",
    "    </p>\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Es pot inferir, a partir del volum d'alcohol, la qualitat del vi?\n",
    "<font color=\"darkblue\">\n",
    "<br>Per tractar de respondre a aquesta pregunta, analitzarem la relació entre les dimensions `alcohol ~ qualitat` i, si escau, crearem un model de regressió lineal per tal de veure com es relacionen.\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alcohol_quality_df = wine_df[['alcohol', 'quality']]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(25, 7))\n",
    "ax.scatter(alcohol_quality_df['alcohol'], alcohol_quality_df['quality'])\n",
    "ax.set_xlabel('Graduació alcoholica')\n",
    "ax.set_ylabel('Qualitat')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"darkblue\">\n",
    "<p>Com podem observar, en aquest cas és obvi que sobre aquestes dades no es pot aplicar un model de regressió lineal, ja que el resultat serà de molt baixa qualitat. Això és degut al fet que la variable qualitat és discreta, i no continua. Tanmateix, s'observa una mena de diagonal que podria fer-nos intuir que la qualitat augmenta així com ho fa la graduació alcohòlica. En cas de voler realitzar una regressió lineal amb les eines usades en aquest exercici, s'hauria d'implementar un codi molt semblant al descrit a la [documentació de sklearn](http://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py).\n",
    "    </p><p>\n",
    "Creiem que, com que ja disposem d'un model per inferir la qualitat del vi, el que podríem fer és tractar d'entrenar el model només amb la graduació alcohòlica i analitzar-ne el comportament.</font><p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_alcohol_train, X_alcohol_test, y_alcohol_train, y_alcohol_test) = split_train_test(alcohol_quality_df['alcohol'], encode_raw_y(raw_y))\n",
    "X_alcohol_train = X_alcohol_train.values.reshape(-1, 1)\n",
    "X_alcohol_test = X_alcohol_test.values.reshape(-1, 1)\n",
    "\n",
    "rfc_alcohol_model = RandomForestClassifier(bootstrap=True, n_estimators = 150, n_jobs=8, random_state=RANDOM_SEED)\n",
    "rfc_alcohol_model.fit(X_alcohol_train, y_alcohol_train)\n",
    "rfc_alcohol_score = rfc_alcohol_model.score(X_alcohol_test, y_alcohol_test)\n",
    "\n",
    "display_precission(rfc_alcohol_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"darkblue\">\n",
    "    <p>\n",
    "Notem com la precisió ha caigut considerablement, com era d'esperar. A més, també hem de tenir present que encara que 67% no sembli un valor especialment baix, no és gaire vàlid. Donat que estam intentant modelar sobre dues classes, un classificador aleatori ens haurà de donar un 50% de precisió, així que aquest és el nostre punt de partida. \n",
    "    </p>\n",
    "    <p>\n",
    "        Com a resposta a la pregunta original, que es demana \"Es pot inferir, a partir del volum d'alcohol, la qualitat del vi?\", amb els resultats obtinguts, tot i no ser una precisió menyspreable, consideram que el model no és suficientment vàlid com per determinar la qualitat del vi només coneixent-ne el volum d'alcohol.\n",
    "    </p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Representació dels resultats a partir de taules i gràfiques.\n",
    "\n",
    "<font color=\"darkblue\"><br>Durant les diferents etapes de neteja i anàlisi hem mostrat les taules i gràfiques adients per entendre el comportament de les accions. Tot i això, a continuació inserim una sèrie de gràfiques addicionals que permeten obtenir encara més coneixement del conjunt de dades.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anàlisi de normalitat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_qq(keys):\n",
    "    if keys is None:\n",
    "        keys = list(wine_df)\n",
    "        \n",
    "    cols = 4\n",
    "    rows = math.ceil(len(keys)/cols)\n",
    "    plt.figure(figsize=(25, 7))\n",
    "    for i, attr_key in enumerate(keys):\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        attr = wine_df[attr_key]\n",
    "        stats.probplot(attr, dist=\"norm\", plot=plt)\n",
    "    plt.show()\n",
    "\n",
    "plot_qq(['alcohol', 'density', 'quality'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"darkblue\">La gràfica Q-Q és molt usada per comprovar la normalitat d'unes sèries de dades. Tanmateix, amb la informació trobada a l'apartat 4.2 ha sigut suficient per veure la normalitat de les dades, així que aquesta implementació ha quedat relegada a una mena d'apèndix. Com més s'aproximen els quantils teòrics a la bisectriu, més normal és la distribució. Fins i tot, podem veure que la distribució de l'atribut de la qualitat, tot i ser discret, és distribueix de forma equitativa al llarg de la bisectriu.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbre de decisió"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"darkblue\">Seleccionat una mostra aleatòria dels 250 arbres del *RandomForest*, observam com l'arbre de decisió és relativament complex. Tot i això, renderitzar-lo és una bona manera de seguir les decisions que aquests pren en funció de les dades d'entrada. Per simplificar el model visualment, podem generar un nou *RandomForest* definit una profunditat màxima dels arbres. Així, òbviament perdrem qualitat de predicció, però és un bon exercici acadèmic.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_tree(tree):\n",
    "    dot_data = StringIO()\n",
    "    export_graphviz(tree, out_file=dot_data,  \n",
    "                    filled=True, rounded=True,\n",
    "                    class_names=CLASSES_NAMES,\n",
    "                    feature_names=list(wine_df.drop(columns='quality')),\n",
    "                    special_characters=True)\n",
    "\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "    display(Image(graph.create_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render random forest sample tree\n",
    "sample_tree = np.random.choice(rfc_model.estimators_)\n",
    "render_tree(sample_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_model_basic_trees = RandomForestClassifier(max_depth=3, bootstrap=True, n_estimators = 150, n_jobs=8, random_state=RANDOM_SEED)\n",
    "rfc_model_basic_trees.fit(X_train, y_train)\n",
    "\n",
    "sample_tree = np.random.choice(rfc_model_basic_trees.estimators_)\n",
    "render_tree(sample_tree)\n",
    "\n",
    "print(\"Precisió del model: {} %\".format(round(rfc_model_basic_trees.score(X_test, y_test)*100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"darkblue\">Ara sí, podem avaluar i seguir fàcilment les decisions que pren aquest nou model. Sorprenentment observem com la precisió del conjunt del *Random Forest* no ha baixat gaire, i es situa en un 71.25%, només 7.5 punts per sota del model original.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriu de confusió\n",
    "\n",
    "<font color=\"darkblue\"><br>Una altra eina molt útil a l'hora d'avaluar models de regressió és la matriu de confusió. Aquesta ens mostra, per cada classe, el nombre de Vertaders positius (*TP*), Falsos postius (*FP*), Vertaders Negatius (*TN*) i Falsos negatius (*FN*).</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Matriu de confusió',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfc_model.predict(X_test)\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plot_confusion_matrix(cnf_matrix, CLASSES_NAMES, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"darkblue\">\n",
    "Podem observar com les prediccions, tant encertades com errònies estan molt equilibrades, així que no sembla que cap de les dues classes sigui un factor determinant a l'hora d'usar el model generat. Això és degut al fet que el *threshold* definit per dir si un vi és bo o dolent és molt proper a la mitjana i coincideix amb la mediana.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Resolució del problema. A partir dels resultats obtinguts, quines són les conclusions? Els resultats permeten respondre al problema?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#1111aa\">\n",
    "    <p>Com hem pogut veure al llarg de tot el document, tots els atributs presents ajuden a determinar la qualitat del vi. Tot i això, hem observat com atributs com els atributs d'alcohol, sulfats o l'acidesa volàtil tenen més pes a la qualitat del vi. A més, aquesta idea ha estat doblement validada, ja que hem descobert aquesta informació mitjançant l'anàlisi de correlacions i mitjançant el *Random Forest*.\n",
    "    </p>\n",
    "    <p>\n",
    "        Per altre costat, hem pogut veure que podem predir la qualitat del vi a partir de l'alcohol amb una precisió del 67%. Tot i que hi ha estudis que donen per bones precisions per sobre del 60%, el nostre llindar és a partir del 80% de precisió per considerar un model com fiable. Per tant, s'hauran de recórrer a més atributs per poder predir la qualitat de forma lineal.\n",
    "    </p>\n",
    "    <p>\n",
    "        Per altra banda, gràcies a respondre les preguntes originals, també hem pogut construir un model de predicció bastant robust que pot classificar els vins entre bons i, diguem-ne, no tan bons, amb una fiabilitat de gairebé el 79%. Com ja s'ha comentat, si a aquest model li donem dades d'anys posteriors a l'any 2009 per entrenar-se, obtindrem un classificador molt fiable per determinar la qualitat dels vins d'enguany.\n",
    "    </p>\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Codi: Cal adjuntar el codi, preferiblement en R, amb el que s’ha realitzat la neteja, anàlisi i representació de les dades. Si ho preferiu, també podeu treballar en Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"darkblue\">\n",
    "Tot el codi emprat en aquesta pràctica es pot trobar en les diferents preguntes en les cel·les precedides amb `In [ ]` i es poden executar des de jupyter o qualsevol terminal interactiva de Python.\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
